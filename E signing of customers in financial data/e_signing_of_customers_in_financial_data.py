# -*- coding: utf-8 -*-
"""E-signing of customers in financial data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v1Wp1m9W3DOq6dmY7EC8yQyk_2qB47kX

# Data Preprocessing

Dataset: https://www.kaggle.com/datasets/yashpaloswal/esigning-of-loanbased-on-financial-history

## importing the libraries and dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset =  pd.read_csv('/content/Financial-Data.csv')

"""## Data Exploration"""

dataset.head()

dataset.shape

dataset.dtypes

dataset.info()

dataset.select_dtypes(include = ['int64','float64']).columns

len(dataset.select_dtypes(include = ['int64','float64']).columns)

dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

# Statistical SUmmary
dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any() # Any missing value

dataset.isnull().values.sum() # number of missing value

"""## Encoding the categorical data"""

dataset.select_dtypes(include = 'object').columns

dataset['pay_schedule'].unique()

# one hot encoding
dataset = pd.get_dummies(data=dataset, drop_first = True, dtype = int)

dataset.head()

dataset.shape

"""## Countplot"""

sns.countplot(x = 'e_signed', data = dataset )

# e signed number
(dataset.e_signed ==1).sum()

# not e signed number
(dataset.e_signed ==0).sum()

"""## Restructure the dataset"""

dataset.head()

dataset['months employed'] = (dataset.months_employed + dataset.years_employed * 12)

dataset.head()

dataset = dataset.drop(columns =['months_employed','years_employed'])

dataset.head()

dataset['personal account months'] = (dataset.personal_account_m + dataset.personal_account_y * 12)

dataset.head()

dataset = dataset.drop(columns =['personal_account_m','personal_account_y'])

dataset.head()

"""## Correlation matrix and Heatmap"""

dataset_2 = dataset.drop(columns = ['Entry_id','e_signed'])

dataset_2.corrwith(dataset['e_signed']).plot.bar(
    figsize = (16,9), title = 'Correlation with e signed', grid= True
)

# heatmap
plt.figure(figsize =(16,9))
ax = sns.heatmap(dataset.corr(),annot = True)

"""## Splitting the dataset"""

dataset.head()

# independent variables/ Matrix of features
x = dataset.drop(columns =['Entry_id','e_signed'])

# Dependent variables/ Target
y = dataset['e_signed']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

"""# Building the model

## Logistics Regression
"""

from sklearn.linear_model import LogisticRegression
classifier_lr = LogisticRegression(random_state = 0)
classifier_lr.fit(x_train,y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test, y_pred)

"""## SVM"""

from sklearn.svm import SVC
classifier_svc = SVC(random_state =0)
classifier_svc.fit(x_train,y_train)

y_pred = classifier_svc.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test, y_pred)

"""## Random forest"""

from sklearn.ensemble import RandomForestClassifier
classifier_rf = RandomForestClassifier(random_state =0)
classifier_rf.fit(x_train,y_train)

y_pred = classifier_rf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test, y_pred)

"""## XGBoost Classifier"""

from xgboost import XGBClassifier
classifier_xgb = XGBClassifier()
classifier_xgb.fit(x_train,y_train)

y_pred = classifier_xgb.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test, y_pred)

"""# Tuning the parameter"""

from sklearn.model_selection import RandomizedSearchCV

parameters = {
    'max_depth': [2,5,6,8,10,12,15],
    'min_child_weight': [1,3,5,7],
    'gamma': [0.00,0.2,0.3,0.4],
    'colsample_bytree': [0.3,0.4,0.5,0.6,0.7],
    'n_estimator': [100,200,300,400,500],
    'subsample': [0.5,0.7,1.0]
}

parameters

random_cv = RandomizedSearchCV(estimator = classifier_xgb, param_distributions = parameters, n_iter=5, scoring ='roc_auc',n_jobs =-1,cv=5,verbose=3)

random_cv.fit(x_train, y_train)

random_cv.best_estimator_

random_cv.best_params_

random_cv.best_score_

"""# Final Model(XGBoost Classifier)"""

from xgboost import XGBClassifier
classifier = XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=0.4, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=5, monotone_constraints=None,
              multi_strategy=None, n_estimator=100, n_estimators=None,
              n_jobs=None, num_parallel_tree=None)
classifier.fit(x_train,y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test, y_pred)

"""# Predicting single observation"""

dataset.head()

single_obs =[[40,1,2500,3,1,600,37000,0.73,0.90,0.5,0.51,0.58,0.38,10,0,0,0,36,30]]

single_obs

classifier.predict(sc.transform(single_obs))