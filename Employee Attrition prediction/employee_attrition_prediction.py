# -*- coding: utf-8 -*-
"""Employee Attrition Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vussh_BybSyqrbw1qKtpbYa9rJ3nNNoO

# Data Preprocessing

Dataset: https://www.kaggle.com/datasets/patelprashant/employee-attrition

## Importing libraries and dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')

"""## Data Exploration"""

dataset.head()

dataset.shape

dataset.columns

dataset.info()

dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

dataset.select_dtypes(include = ['int64']).columns

len(dataset.select_dtypes(include = ['int64']).columns)

# statistical summary
dataset.describe()

"""## Restructuring the **dataset**"""

dataset.head()

# Dropping the unnecessary columns
# EmployeeCount, EmployeeNumber, Over18, StandardHours,
dataset['EmployeeCount'].nunique()

dataset['EmployeeCount'].unique()

dataset['Over18'].unique()

dataset['Over18'].nunique()

dataset['StandardHours'].nunique()

dataset['StandardHours'].unique()

dataset = dataset.drop(columns= ['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'])

dataset.shape

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

"""## Countplot"""

sns.countplot(x = 'Attrition', data = dataset)

# Employees left the company
(dataset.Attrition == 'Yes').sum()

# Employees still at the company
(dataset.Attrition == 'No').sum()

plt.figure(figsize = (20,20))
plt.subplot(311)
sns.countplot(x = 'Department', hue = 'Attrition', data = dataset)

plt.subplot(312)
sns.countplot(x = 'JobRole', hue = 'Attrition', data = dataset)

plt.subplot(313)
sns.countplot(x = 'JobSatisfaction', hue = 'Attrition', data = dataset)

"""## Corealation and Heatmap"""

corr = dataset.corr(numeric_only=True)

# Corelation Matrix
plt.figure(figsize = (16,9))
ax =sns.heatmap(corr, annot =True, cmap = 'coolwarm')

"""## Dealing with categorical data"""

dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

dataset.shape

# one hot encoding
dataset = pd.get_dummies(data = dataset, drop_first = True,  dtype = int)

dataset.shape

len(dataset.select_dtypes(include = 'object').columns)

dataset.head()

dataset.rename(columns = {'Attrition_Yes': 'Attrition'}, inplace = True)

dataset.head()

"""## Splitting the dataset"""

# Matrix of feature
x= dataset.drop(columns = 'Attrition')

# target variables
y = dataset['Attrition']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

"""# Building the Model

## Logistic regression
"""

from sklearn.linear_model import LogisticRegression
classifier_lr = LogisticRegression(random_state=0)
classifier_lr.fit(x_train,y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix

acc= accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test, y_pred)

cm

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
classifier_rf = RandomForestClassifier(random_state = 0)
classifier_rf.fit(x_train,y_train)

y_pred = classifier_rf.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix

acc= accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test, y_pred)

cm

"""## SVM"""

from sklearn.svm import SVC
classifier_svc = SVC(random_state= 0)
classifier_svc.fit(x_train,y_train)

y_pred = classifier_svc.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix

acc= accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test, y_pred)

cm

"""# Randomized search to find best parameters(Logistic Regression)"""

from sklearn.model_selection import RandomizedSearchCV

parameters = {
    'penalty': ['l1','l2', 'elasticnet', 'none'],
    'C' :[0.25,0.5,0.75,1,1.25,1.5,1.75,2],
    'solver':['newton-cg','lbfgs','liblinear','sag','saga'],
    'max_iter': [50,100,500,2000,5000]
}

parameters

random_cv = RandomizedSearchCV(estimator = classifier_lr, param_distributions = parameters, n_iter=10, scoring = 'roc_auc',n_jobs = -1, cv= 5, verbose = 3)

random_cv.fit(x_train,y_train)

random_cv.best_estimator_

random_cv.best_params_

random_cv.best_score_

"""# Final Model"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(C=0.5, max_iter=2000, random_state=0, solver='sag')
classifier.fit(x_train,y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix

acc= accuracy_score(y_test,y_pred)

acc

cm = confusion_matrix(y_test, y_pred)

cm

"""# Predicting single observation"""

dataset.head()

single_obs = [[41,110,1,2,2,94,3,2,4,5993,19479,8,11,3,1,0,8,0,1,6,4,0,5,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1]]

single_obs

classifier.predict(sc.transform(single_obs))

# 1 which means leaving the company